{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f332449b-6317-460e-82af-f82492b4ad93",
      "metadata": {
        "trusted": false
      },
      "source": [
        "# Calculate embedding vectors for mixed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1d934105-10b2-4353-9de9-6d456ca74ba4",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pathvalidate in /home/jonas/.conda/envs/bachelor3/lib/python3.12/site-packages (3.2.3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(obj)>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install pathvalidate\n",
        "import json\n",
        "from functools import reduce\n",
        "# conda activate instructor\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import trange, tqdm\n",
        "from time import sleep\n",
        "import statistics\n",
        "import pickle\n",
        "from tqdm.autonotebook import tqdm\n",
        "from pathvalidate import sanitize_filename\n",
        "\n",
        "from IPython.display import display\n",
        "import time\n",
        "\n",
        "flat_map = lambda f, xs: reduce(lambda a, b: a + b, map(f, xs))\n",
        "\n",
        "import json\n",
        "import IPython.core.formatters\n",
        "\n",
        "class JsonDumpTryingFormatter(\n",
        "    IPython.core.formatters.PlainTextFormatter\n",
        "):\n",
        "    def __call__(self, obj):\n",
        "        try:\n",
        "            return json.dumps(\n",
        "                obj,\n",
        "                indent=2,\n",
        "                default=self._json_default\n",
        "            )\n",
        "        except TypeError:\n",
        "            return super().__call__(obj)\n",
        "\n",
        "    def _json_default(self, obj):\n",
        "        if isinstance(obj, set):\n",
        "            return list(obj)\n",
        "        raise TypeError(f\"Unsupported type {type(obj)}\")\n",
        "\n",
        "_ipy = IPython.get_ipython()\n",
        "_formatters = _ipy.display_formatter.formatters\n",
        "_formatters[\"text/plain\"] = JsonDumpTryingFormatter()\n",
        "import IPython\n",
        "_ipy = IPython.get_ipython()\n",
        "_formatters = _ipy.display_formatter.formatters\n",
        "_json_formatter = _formatters[\"application/json\"]\n",
        "_json_formatter.for_type(dict, lambda obj: obj)\n",
        "_json_formatter.for_type(list, lambda obj: obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa84ecb-626d-4a2a-a6f7-4956d0086635",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#load test data\n",
        "#!pip install dbrepo\n",
        "from dbrepo.RestClient import RestClient\n",
        "client = RestClient(endpoint=\"https://test.dbrepo.tuwien.ac.at\", username=\"11905148\", password=\"nixda\")\n",
        "\n",
        "\n",
        "table_data = client.get_table_data(database_id =\"e31b2788-e1da-4a4a-9892-d2b5a1216df6\", table_id=\"41c10fad-83e7-4df3-a188-eb872e05646a\",size=1000)\n",
        "\n",
        "data = dict(table_data)\n",
        "\n",
        "cyber = []\n",
        "krimisi = []\n",
        "innotech = []\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for i in range(len(data['bh_category'])):\n",
        "    all_data.append({\"CC_filename\": data['cc_filename'][i], \"content\": data['content'][i], \"BH_category\": data['bh_category'][i],\"CC_normalized_url\": data['cc_normalized_url'][i],\"is_relevant\": data['is_relevant'][i]})\n",
        "\n",
        "#Local test data\n",
        "\"\"\"\n",
        "with open(\"savedata.json\") as file:\n",
        "    data = json.loads(file.read())\n",
        "all_data = data\n",
        "\"\"\"\n",
        "\n",
        "irr = [x for x in all_data if not x['is_relevant']][:10]\n",
        "\n",
        "rel = [x for x in all_data if x['is_relevant']][:10]\n",
        "\n",
        "test_data = []+irr+rel\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8db538f8-cd8d-44e3-8910-d8e9cd3f3388",
      "metadata": {
        "trusted": false
      },
      "source": [
        "### Data format\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"BH_category\":[],\n",
        "        \"CC_filename\":\"\",\n",
        "        \"CC_normalized_url\":\"\",\n",
        "        \"is_relevant\":false,\n",
        "        \"content\":\"\"\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3409f12c-8627-4857-a694-122b45aa419e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# embeddings cache\n",
        "\n",
        "def generate_embeddings(model_name, long_passage=False):\n",
        "\n",
        "    model = SentenceTransformer(model_name,device=\"cpu\",trust_remote_code=True)\n",
        "\n",
        "    if long_passage:\n",
        "        embeds = model.encode([\"Represent this sentence for searching relevant passages: Articles or news about crises, military or security.\",\n",
        "                            \"Represent this sentence for searching relevant passages: Articles or news about new innovations and technology.\",\n",
        "                            \"Represent this sentence for searching relevant passages: Articles or news about cyber security.\"])\n",
        "    else:\n",
        "        embeds = model.encode([\"crises, military or security\",\"new innovations or technology\",\"cyber security\"])\n",
        "    \n",
        "    \n",
        "    embedding_cache = {\n",
        "        \"cyber\":embeds[2],\n",
        "        \"krimisi\":embeds[0],\n",
        "        \"innotech\":embeds[1]\n",
        "    }\n",
        "    all_embeddings = []\n",
        "    \n",
        "    for rec in tqdm(test_data, total=len(test_data), desc=\"Processing records\"):\n",
        "        content = rec[\"content\"]\n",
        "        url = rec[\"CC_normalized_url\"]\n",
        "        is_relevant = rec[\"is_relevant\"]\n",
        "        categories = [\"cyber\",\"krimisi\",\"innotech\"] #rec[\"BH_category\"]\n",
        "        embeddings = model.encode([content])\n",
        "        all_embeddings.append({\n",
        "            \"model\":model_name,\n",
        "            \"categories\":categories,\n",
        "            \"categories_embedding\": [embedding_cache[category] for category in categories] if rec[\"BH_category\"] else list(embedding_cache.values()),\n",
        "            \"url\":url,\n",
        "            \"content_embedding\":embeddings[0],\n",
        "            \"is_relevant\": is_relevant\n",
        "        })\n",
        "    # save for further processing\n",
        "    embedings_output_path = f\"model_data/{sanitize_filename(model_name)}.pickle\"\n",
        "    if long_passage:\n",
        "        embedings_output_path = f\"model_data/{sanitize_filename(model_name)}.pickle_long_passage\"\n",
        "\n",
        "    with open(embedings_output_path,\"wb\") as file:\n",
        "        pickle.dump(all_embeddings,file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "34f3e94c-eb41-4abb-81cd-6291791ff963",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-28 23:50:33,503 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: ./custom/test_encoder_only_base_bge-large-en-v1.5\n",
            "2025-04-28 23:50:33,504 sentence_transformers.SentenceTransformer WARNING No sentence-transformers model found with name ./custom/test_encoder_only_base_bge-large-en-v1.5. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]t/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s],  2.62it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s],  2.63it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s],  2.64it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s],  2.66it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s],  2.64it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s],  2.66it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s],  2.68it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s],  2.66it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s],  2.67it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]3,  2.64it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]3,  2.65it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]3,  2.66it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]2,  2.65it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]2,  2.66it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]1,  2.69it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]1,  2.70it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]1,  2.70it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]0,  2.70it/s]\n",
            "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]0,  2.68it/s]\n",
            "Processing records: 100%|██████████| 20/20 [00:07<00:00,  2.67it/s]\n"
          ]
        }
      ],
      "source": [
        "#model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\",device=\"cpu\")\n",
        "#model = SentenceTransformer(\"sentence-transformers/multi-qa-mpnet-base-cos-v1\",device=\"cuda\")\n",
        "\n",
        "\n",
        "model_name = \"./custom/test_encoder_only_base_bge-large-en-v1.5\"\n",
        "#generate_embeddings(model_name)\n",
        "#model_name = \"BAAI/bge-large-en-v1.5\"\n",
        "generate_embeddings(model_name,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d21fcb-7a4f-4cc2-b02e-6ef923332446",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bachelor3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
